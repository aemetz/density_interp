{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/tem7290/.conda/envs/posydon/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow.keras import layers, losses, models, optimizers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams as rc\n",
    "rc['font.size']=12\n",
    "import os\n",
    "from posydon.grids.psygrid import PSyGrid\n",
    "from posydon.interpolation.IF_interpolation import BaseIFInterpolator\n",
    "import warnings\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/projects/b1119/eteng/psygrid_dataset\")\n",
    "data = np.load(\"normalized_logrho_profiles.npy\",allow_pickle=True)\n",
    "sliced = list(data)\n",
    "data_trunc = random.sample(sliced, k=5000)\n",
    "data_trunc = np.array(data_trunc)\n",
    "valid = np.load(\"normalized_logrho_validation_profiles.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhoProf:\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        # will have to make this take in a custom path\n",
    "        self.model = BaseIFInterpolator(filename = \"/home/tem7290/b1119/prs5019/POSYDON/data/POSYDON_data/CO-HeMS/interpolators/linear3c_kNN/grid_0.0142.pkl\")\n",
    "\n",
    "        self.init_unstable = False\n",
    "        self.init_stable = False\n",
    "        self.init_initial = False\n",
    "        self.init_no = False\n",
    "\n",
    "        self.mass_points = data[0].get('m_arr')\n",
    "        \n",
    "    # methods        \n",
    "    def _vars(self, mt_profs, mt_string, prof_true, final_mass, rho_min, rho_max, rho_minmax, linx, x):\n",
    "        if mt_profs == []:\n",
    "            for prof in self.data:\n",
    "                temp_in = np.transpose([prof.get('m1'), prof.get('m2'), prof.get('p')])\n",
    "                mt_type = self.model.test_classifier(\"interpolation_class\", np.array([temp_in]))\n",
    "                if mt_type == mt_string:\n",
    "                    mt_profs.append(prof)\n",
    "                    prof_true.append(prof.get('logrho_arr'))\n",
    "                    final_mass.append(np.log10(prof.get('final_mass')))\n",
    "                    rho_min.append(prof.get('min_logrho'))\n",
    "                    rho_max.append(prof.get('max_logrho'))\n",
    "                    rho_minmax.append([prof.get('min_logrho'), prof.get('max_logrho')])\n",
    "                    linx.append(temp_in)\n",
    "                    x.append(np.log10(temp_in))\n",
    "\n",
    "\n",
    "    def _pca(self, prof_true):\n",
    "        pca = PCA(n_components=6).fit(prof_true)\n",
    "        prof_low_unscaled = pca.transform(prof_true)\n",
    "        sc = np.std(prof_low_unscaled,axis=0)\n",
    "        prof_low = prof_low_unscaled/sc\n",
    "        return pca, sc, prof_low\n",
    "                                      \n",
    "    def _model(self, x, prof_low):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(15,input_dim=3,activation=None),\n",
    "            layers.Dense(15,input_dim=15,activation=\"relu\"),\n",
    "            layers.Dense(15,input_dim=15,activation=\"relu\"),\n",
    "            layers.Dense(15,input_dim=15,activation=\"tanh\"),\n",
    "            layers.Dense(10,input_dim=10,activation=\"tanh\"),\n",
    "            layers.Dense(10,input_dim=10,activation=\"tanh\"),\n",
    "            layers.Dense(6,activation=None)\n",
    "        ])\n",
    "                                      \n",
    "        loss_mse = losses.MeanSquaredError()\n",
    "                                      \n",
    "        model.compile(optimizers.Adam(clipnorm=1),loss=loss_mse)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40)\n",
    "        history = model.fit(x,prof_low,epochs=3000,callbacks=[callback],verbose=0)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.show()\n",
    "        return model\n",
    "                                      \n",
    "    def _model_mass(self, x, final_mass):\n",
    "        model_mass = models.Sequential([\n",
    "            layers.Dense(10,input_dim=3,activation=None),\n",
    "            layers.Dense(10,input_dim=10,activation='relu'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(1,activation=None)\n",
    "        ])\n",
    "                                      \n",
    "        loss_mse = losses.MeanSquaredError()\n",
    "        \n",
    "        model_mass.compile(optimizers.Adam(clipnorm=1),loss=\"mse\")\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40)\n",
    "        history = model_mass.fit(x,final_mass,epochs=2000,callbacks=[callback],verbose=0)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.show()\n",
    "        return model_mass\n",
    "                                      \n",
    "    def _model_rho(self, x, rho_minmax):\n",
    "        print('entering model rho')\n",
    "        model_rho = models.Sequential([\n",
    "            layers.Dense(10,input_dim=3,activation='relu'),\n",
    "            layers.Dense(10,input_dim=10,activation='relu'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(10,input_dim=10,activation='tanh'),\n",
    "            layers.Dense(2,activation=None)\n",
    "        ])\n",
    "\n",
    "        loss_mse = losses.MeanSquaredError()\n",
    "        \n",
    "        model_rho.compile(optimizers.Adam(clipnorm=1),loss=\"mse\")\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40)\n",
    "        history = model_rho.fit(x,rho_minmax,epochs=2000,callbacks=[callback],verbose=0)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.show()\n",
    "        return model_rho\n",
    "\n",
    "    def _pred_profiles(self, pca, model, model_mass, model_rho, lin_x, sc):\n",
    "        x = np.log10(lin_x)\n",
    "        regress_mass = lambda x: model_mass(x)\n",
    "        final_log_masses = regress_mass(x)\n",
    "        final_linear_masses = 10**final_log_masses\n",
    "\n",
    "        regress_rho = lambda x: model_rho(x)\n",
    "        min_rho = np.array(regress_rho(x)[:,0])\n",
    "        max_rho = np.array(regress_rho(x)[:,1])\n",
    "        min_rho.shape, max_rho.shape = (len(min_rho), 1), (len(max_rho), 1)\n",
    "\n",
    "        regress = lambda x: model(x)\n",
    "        scaled_pca_weights = regress(x)\n",
    "        norm_profiles = pca.inverse_transform(scaled_pca_weights*sc)\n",
    "\n",
    "        minrho_profiles = min_rho*norm_profiles\n",
    "        maxrho_profiles = max_rho*norm_profiles\n",
    "\n",
    "        density_profiles = norm_profiles*(maxrho_profiles-minrho_profiles) + maxrho_profiles\n",
    "        xcoords = self.mass_points*final_linear_masses[:,np.newaxis]\n",
    "\n",
    "        return max_rho, xcoords, density_profiles\n",
    "        \n",
    "    def _pred_unstable_mt(self, inputs):\n",
    "        if self.init_unstable == False:\n",
    "            self.unstable_mt_profs, self.unstable_prof_true, self.unstable_final_mass, self.unstable_rho_min, \\\n",
    "            self.unstable_rho_max, self.unstable_rho_minmax, self.unstable_linx, self.unstable_x = [], [], [], [], [], [], [], []\n",
    "            \n",
    "            self.unst_val_mt_profs, self.unst_val_prof_true, self.unst_val_final_mass, self.unst_val_rho_min, \\\n",
    "            self.unst_val_rho_max, self.unst_val_rho_minmax, self.unst_val_linx, self.unst_val_x = [], [], [], [], [], [], [], []\n",
    "\n",
    "            self._vars(self.unstable_mt_profs, 'unstable_MT', self.unstable_prof_true, self.unstable_final_mass,\n",
    "                       self.unstable_rho_min, self.unstable_rho_max, self.unstable_rho_minmax, self.unstable_linx, self.unstable_x)\n",
    "            \n",
    "            self._vars(self.unst_val_mt_profs, 'unstable_MT', self.unst_val_prof_true, self.unst_val_final_mass,\n",
    "                       self.unst_val_rho_min, self.unst_val_rho_max, self.unst_val_rho_minmax, self.unst_val_linx, self.unst_val_x)\n",
    "            \n",
    "            self.unstable_mt_profs = np.array(self.unstable_mt_profs)\n",
    "            self.unstable_prof_true = np.array(self.unstable_prof_true)\n",
    "            self.unstable_final_mass = np.array(self.unstable_final_mass)\n",
    "            self.unstable_rho_min = np.array(self.unstable_rho_min)\n",
    "            self.unstable_rho_max = np.array(self.unstable_rho_max)\n",
    "            self.unstable_rho_minmax = np.array(self.unstable_rho_minmax)\n",
    "            self.unstable_linx = np.array(self.unstable_linx)\n",
    "            self.unstable_x = np.array(self.unstable_x)\n",
    "            \n",
    "            self.unst_val_mt_profs = np.array(self.unst_val_mt_profs)\n",
    "            self.unst_val_prof_true = np.array(self.unst_val_prof_true)\n",
    "            self.unst_val_final_mass = np.array(self.unst_val_final_mass)\n",
    "            self.unst_val_rho_min = np.array(self.unst_val_rho_min)\n",
    "            self.unst_val_rho_max = np.array(self.unst_val_rho_max)\n",
    "            self.unst_val_rho_minmax = np.array(self.unst_val_rho_minmax)\n",
    "            self.unst_val_linx = np.array(self.unst_val_linx)\n",
    "            self.unst_val_x = np.array(self.unst_val_x)\n",
    "            \n",
    "            self.unstable_pca, self.unstable_sc, self.unstable_prof_low = self._pca(self.unstable_prof_true)\n",
    "            self.unst_val_pca, self.unst_val_sc, self.unst_val_prof_low = self._pca(self.unst_val_prof_true)\n",
    "            self.unstable_model = self._model(self.unstable_x, self.unstable_prof_low)\n",
    "            self.unstable_model_mass = self._model_mass(self.unstable_x, self.unstable_final_mass)\n",
    "            self.unstable_model_rho = self._model_rho(self.unstable_x, self.unstable_rho_minmax)\n",
    "            \n",
    "            self.init_unstable = True\n",
    "        \n",
    "        return self._pred_profiles(self.unstable_pca, self.unstable_model, self.unstable_model_mass, self.unstable_model_rho,\\\n",
    "                                  inputs, self.unstable_sc)\n",
    "    \n",
    "    def _pred_stable_mt(self, inputs):\n",
    "        if self.init_stable == False:\n",
    "            self.stable_mt_profs, self.stable_prof_true, self.stable_final_mass, self.stable_rho_min, \\\n",
    "            self.stable_rho_max, self.stable_rho_minmax, self.stable_linx, self.stable_x = [], [], [], [], [], [], [], []\n",
    "\n",
    "            self._vars(self.stable_mt_profs, 'stable_MT', self.stable_prof_true, self.stable_final_mass,\n",
    "                       self.stable_rho_min, self.stable_rho_max, self.stable_rho_minmax, self.stable_linx, self.stable_x)\n",
    "            \n",
    "            self.stable_mt_profs = np.array(self.stable_mt_profs)\n",
    "            self.stable_prof_true = np.array(self.stable_prof_true)\n",
    "            self.stable_final_mass = np.array(self.stable_final_mass)\n",
    "            self.stable_rho_min = np.array(self.stable_rho_min)\n",
    "            self.stable_rho_max = np.array(self.stable_rho_max)\n",
    "            self.stable_rho_minmax = np.array(self.stable_rho_minmax)\n",
    "            self.stable_linx = np.array(self.stable_linx)\n",
    "            self.stable_x = np.array(self.stable_x)\n",
    "            \n",
    "            self.stable_pca, self.stable_sc, self.stable_prof_low = self._pca(self.stable_prof_true)\n",
    "            self.stable_model = self._model(self.stable_x, self.stable_prof_low)\n",
    "            self.stable_model_mass = self._model_mass(self.stable_x, self.stable_final_mass)\n",
    "            self.stable_model_rho = self._model_rho(self.stable_x, self.stable_rho_minmax)\n",
    "            \n",
    "            self.init_stable = True\n",
    "        \n",
    "        return self._pred_profiles(self.stable_pca, self.stable_model, self.stable_model_mass, self.stable_model_rho,\\\n",
    "                                  inputs, self.stable_sc)\n",
    "    \n",
    "    def _pred_initial_mt(self, inputs):\n",
    "        if self.init_initial == False:\n",
    "            self.initial_mt_profs, self.initial_prof_true, self.initial_final_mass, self.initial_rho_min, \\\n",
    "            self.initial_rho_max, self.initial_rho_minmax, self.initial_linx, self.initial_x = [], [], [], [], [], [], [], []\n",
    "\n",
    "            self._vars(self.initial_mt_profs, 'initial_MT', self.initial_prof_true, self.initial_final_mass,\n",
    "                       self.initial_rho_min, self.initial_rho_max, self.initial_rho_minmax, self.initial_linx, self.initial_x)\n",
    "            \n",
    "            self.initial_mt_profs = np.array(self.initial_mt_profs)\n",
    "            self.initial_prof_true = np.array(self.initial_prof_true)\n",
    "            self.initial_final_mass = np.array(self.initial_final_mass)\n",
    "            self.initial_rho_min = np.array(self.initial_rho_min)\n",
    "            self.initial_rho_max = np.array(self.initial_rho_max)\n",
    "            self.initial_rho_minmax = np.array(self.initial_rho_minmax)\n",
    "            self.initial_linx = np.array(self.initial_linx)\n",
    "            self.initial_x = np.array(self.initial_x)\n",
    "            \n",
    "            self.initial_pca, self.initial_sc, self.initial_prof_low = self._pca(self.initial_prof_true)\n",
    "            self.initial_model = self._model(self.initial_x, self.initial_prof_low)\n",
    "            self.initial_model_mass = self._model_mass(self.initial_x, self.initial_final_mass)\n",
    "            self.initial_model_rho = self._model_rho(self.initial_x, self.initial_rho_minmax)\n",
    "            \n",
    "            self.init_initial = True\n",
    "        \n",
    "        return self._pred_profiles(self.initial_pca, self.initial_model, self.initial_model_mass, self.initial_model_rho,\\\n",
    "                                  inputs, self.initial_sc)\n",
    "    \n",
    "    def _pred_no_mt(self, inputs):\n",
    "        if self.init_no == False:\n",
    "            self.no_mt_profs, self.no_prof_true, self.no_final_mass, self.no_rho_min, \\\n",
    "            self.no_rho_max, self.no_rho_minmax, self.no_linx, self.no_x = [], [], [], [], [], [], [], []\n",
    "\n",
    "            self._vars(self.no_mt_profs, 'no_MT', self.no_prof_true, self.no_final_mass,\n",
    "                       self.no_rho_min, self.no_rho_max, self.no_rho_minmax, self.no_linx, self.no_x)\n",
    "            \n",
    "            self.no_mt_profs = np.array(self.no_mt_profs)\n",
    "            self.no_prof_true = np.array(self.no_prof_true)\n",
    "            self.no_final_mass = np.array(self.no_final_mass)\n",
    "            self.no_rho_min = np.array(self.no_rho_min)\n",
    "            self.no_rho_max = np.array(self.no_rho_max)\n",
    "            self.no_rho_minmax = np.array(self.no_rho_minmax)\n",
    "            self.no_linx = np.array(self.no_linx)\n",
    "            self.no_x = np.array(self.no_x)\n",
    "            \n",
    "            self.no_pca, self.no_sc, self.no_prof_low = self._pca(self.no_prof_true)\n",
    "            self.no_model = self._model(self.no_x, self.no_prof_low)\n",
    "            self.no_model_mass = self._model_mass(self.no_x, self.no_final_mass)\n",
    "            self.no_model_rho = self._model_rho(self.no_x, self.no_rho_minmax)\n",
    "            \n",
    "            self.init_no = True\n",
    "        \n",
    "        return self._pred_profiles(self.no_pca, self.no_model, self.no_model_mass, self.no_model_rho,\\\n",
    "                                  inputs, self.no_sc)\n",
    "    \n",
    "    def pred_prof(self, inputs):\n",
    "        # currently this only works for inputs in [[m1,m2,p]] format. double brackets, one 3d input\n",
    "        # can adjust to account for more later by returning a list of lists of xcoords, profiles\n",
    "        # where this function calls the _pred functions through iterating over the inputs and appends the xcoords and profiles\n",
    "        # to what will be the output\n",
    "        if len(inputs) == 1:\n",
    "            mt_type = self.model.test_classifier(\"interpolation_class\", np.array(inputs))\n",
    "            if mt_type == 'unstable_MT':\n",
    "                print('unstable')\n",
    "                return self._pred_unstable_mt(inputs)\n",
    "            elif mt_type == 'stable_MT':\n",
    "                print('stable')\n",
    "                return self._pred_stable_mt(inputs)\n",
    "            elif mt_type == 'initial_MT':\n",
    "                print('initial')\n",
    "                return self._pred_initial_mt(inputs)\n",
    "            elif mt_type == 'no_MT':\n",
    "                print('no')\n",
    "                return self._pred_no_mt(inputs)\n",
    "        elif len(inputs) > 1:\n",
    "            unst = []\n",
    "            st = []\n",
    "            init = []\n",
    "            no = []\n",
    "            for inp in inputs:\n",
    "                mt_type = self.model.test_classifier(\"interpolation_class\", np.array([inp]))\n",
    "                if mt_type == 'unstable_MT':\n",
    "                    unst.append(self._pred_unstable_mt(inp))\n",
    "                elif mt_type == 'stable_MT':\n",
    "                    st.append(self._pred_stable_mt(inp))\n",
    "                elif mt_type == 'initial_MT':\n",
    "                    init.append(self._pred_initial_mt(inputs))\n",
    "                elif mt_type == 'no_MT':\n",
    "                    no.append(self._pred_no_mt(inputs))\n",
    "                    \n",
    "            type_return = self.model.test_classifier(\"interpolation_class\", np.array([inputs[0]]))\n",
    "            if type_return == 'unstable_MT':\n",
    "                return unst\n",
    "            elif type_return == 'stable_MT':\n",
    "                return st\n",
    "            elif type_return == 'initial_MT':\n",
    "                return init\n",
    "            elif type_return == 'no_MT':\n",
    "                return no\n",
    "    \n",
    "    # debugging\n",
    "    def call_vars(self):\n",
    "        self.unstable_mt_profs, self.unstable_prof_true, self.unstable_final_mass, self.unstable_rho_min, \\\n",
    "            self.unstable_rho_max, self.unstable_rho_minmax, self.unstable_linx, self.unstable_x = [], [], [], [], [], [], [], []\n",
    "        \n",
    "        self._vars(self.unstable_mt_profs, 'unstable_MT', self.unstable_prof_true, self.unstable_final_mass,\n",
    "                       self.unstable_rho_min, self.unstable_rho_max, self.unstable_rho_minmax, self.unstable_linx, self.unstable_x)\n",
    "        \n",
    "        self.unstable_mt_profs = np.array(self.unstable_mt_profs)\n",
    "        self.unstable_prof_true = np.array(self.unstable_prof_true)\n",
    "        self.unstable_final_mass = np.array(self.unstable_final_mass)\n",
    "        self.unstable_rho_min = np.array(self.unstable_rho_min)\n",
    "        self.unstable_rho_max = np.array(self.unstable_rho_max)\n",
    "        self.unstable_rho_minmax = np.array(self.unstable_rho_minmax)\n",
    "        self.unstable_linx = np.array(self.unstable_linx)\n",
    "        self.unstable_x = np.array(self.unstable_x)\n",
    "        \n",
    "    def print_vars(self):\n",
    "        return self.unstable_mt_profs, 'unstable_MT', self.unstable_prof_true, self.unstable_final_mass, \\\n",
    "                    self.unstable_rho_min, self.unstable_rho_max, self.unstable_rho_minmax, self.unstable_linx, self.unstable_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unstable\n",
      "entering model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 11:35:56.315027: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-11 11:35:56.317396: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-11 11:35:56.322722: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-08-11 11:35:56.796962: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-11 11:35:56.797719: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering model mass\n"
     ]
    }
   ],
   "source": [
    "valid_m1 = [prof.get('m1') for prof in valid]\n",
    "valid_m2 = [prof.get('m2') for prof in valid]\n",
    "valid_p = [prof.get('p') for prof in valid]\n",
    "valid_x = [[valid_m1[i],valid_m2[i],valid_p[i]] for i in range(len(valid_m1))]\n",
    "\n",
    "model = BaseIFInterpolator(filename = \"/home/tem7290/b1119/prs5019/POSYDON/data/POSYDON_data/CO-HeMS/interpolators/linear3c_kNN/grid_0.0142.pkl\")\n",
    "unst_linx = []\n",
    "st_linx = []\n",
    "in_linx = []\n",
    "no_linx = []\n",
    "unst_m1list = []\n",
    "unst_m2list = []\n",
    "unst_plist = []\n",
    "st_m1list = []\n",
    "st_m2list = []\n",
    "st_plist = []\n",
    "in_m1list = []\n",
    "in_m2list = []\n",
    "in_plist = []\n",
    "no_m1list = []\n",
    "no_m2list = []\n",
    "no_plist = []\n",
    "unst_maxlist = []\n",
    "st_maxlist = []\n",
    "in_maxlist = []\n",
    "no_maxlist = []\n",
    "\n",
    "glow = RhoProf(data_trunc)\n",
    "glow.pred_prof([[13, 1, 0.08]])\n",
    "\n",
    "for inp in valid_x:\n",
    "    maxrho, xcoords, profiles = glow.pred_prof([inp])\n",
    "    \n",
    "    if model.test_classifier(\"interpolation_class\", np.array([inp])) == 'unstable_MT':\n",
    "        unst_linx.append(inp)\n",
    "        unst_m1list.append(inp[0])\n",
    "        unst_m2list.append(inp[1])\n",
    "        unst_plist.append(inp[2])\n",
    "        unst_maxlist.append(maxrho)\n",
    "        \n",
    "    elif model.test_classifier(\"interpolation_class\", np.array([inp])) == 'stable_MT':\n",
    "        st_linx.append(inp)\n",
    "        st_m1list.append(inp[0])\n",
    "        st_m2list.append(inp[1])\n",
    "        st_plist.append(inp[2])\n",
    "        st_maxlist.append(maxrho)\n",
    "        \n",
    "    elif model.test_classifier(\"interpolation_class\", np.array([inp])) == 'initial_MT':\n",
    "        in_linx.append(inp)\n",
    "        in_m1list.append(inp[0])\n",
    "        in_m2list.append(inp[1])\n",
    "        in_plist.append(inp[2])\n",
    "        in_maxlist.append(maxrho)\n",
    "        \n",
    "    elif model.test_classifier(\"interpolation_class\", np.array([inp])) == 'no_MT':\n",
    "        no_linx.append(inp)\n",
    "        no_m1list.append(inp[0])\n",
    "        no_m2list.append(inp[1])\n",
    "        no_plist.append(inp[2])\n",
    "        no_maxlist.append(maxrho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unst_maxlist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_maxlist = [no_maxlist[i][0][0] for i in range(len(no_maxlist))]\n",
    "in_maxlist = [in_maxlist[i][0][0] for i in range(len(in_maxlist))]\n",
    "st_maxlist = [st_maxlist[i][0][0] for i in range(len(st_maxlist))]\n",
    "unst_maxlist = [unst_maxlist[i][0][0] for i in range(len(unst_maxlist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTIONS BASED ON VALIDATION DATA\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=unst_m1list,\n",
    "        y=unst_plist,\n",
    "        z=unst_maxlist,\n",
    "        title='Max rho predictions'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(scene = dict(\n",
    "                        xaxis_title = 'm1',\n",
    "                        yaxis_title = 'p', \n",
    "                        zaxis_title = 'max rho'))\n",
    "fig.show()\n",
    "# https://www.youtube.com/watch?v=KTDlae_aidQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# All 4 predictions\n",
    "fig = go.Figure(\n",
    "    data = [\n",
    "        go.Scatter3d(x=unst_m1list, y=unst_plist, z=unst_maxlist, \n",
    "                     name='Unstable', mode='markers'),\n",
    "        go.Scatter3d(x=st_m1list, y=st_plist, z=st_maxlist, \n",
    "                     name='Stable', mode='markers'),\n",
    "        go.Scatter3d(x=in_m1list, y=in_plist, z=in_maxlist, \n",
    "                     name='Initial', mode='markers'),\n",
    "        go.Scatter3d(x=no_m1list, y=no_plist, z=no_maxlist, \n",
    "                     name='No', mode='markers')\n",
    "    ]\n",
    ")\n",
    "fig.show()\n",
    "# https://stackoverflow.com/questions/71900162/plotly-how-to-plot-multiple-lines-with-different-x-arrays-on-the-same-y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data = [\n",
    "        go.Scatter3d(x=unst_m1list, y=unst_m2list, z=unst_plist, \n",
    "                     name='Unstable', mode='markers', color=unst_maxlist),\n",
    "        go.Scatter3d(x=st_m1list, y=st_m2list, z=st_plist, \n",
    "                     name='Stable', mode='markers', color=st_maxlist),\n",
    "        go.Scatter3d(x=in_m1list, y=in_m2list, z=in_plist, \n",
    "                     name='Initial', mode='markers', color=in_maxlist),\n",
    "        go.Scatter3d(x=no_m1list, y=no_m2list, z=no_plist, \n",
    "                     name='No', mode='markers', color=no_maxlist)\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posydon",
   "language": "python",
   "name": "posydon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
